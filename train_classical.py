
import numpy as np
import pandas as pd

from sklearn.linear_model import LinearRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

from sklearn.preprocessing import Normalizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from prettytable import PrettyTable
from joblib import dump, load

np.random.seed(1337) # for reproducibility


def generate_train_test_data(trainfile, testfile):
    traindata = pd.read_csv(trainfile, header=None)
    testdata = pd.read_csv(testfile, header=None)

    X_train = np.array(traindata.iloc[:, 1:]).astype(float)
    y_train = np.array(traindata.iloc[:, 0]).astype(float)
    X_test = np.array(testdata.iloc[:, 1:]).astype(float)
    y_test = np.array(testdata.iloc[:, 0]).astype(float)

    X_train = Normalizer().fit(X_train).transform(X_train)
    X_test = Normalizer().fit(X_test).transform(X_test)

    return X_train, y_train, X_test, y_test


def train_model(model, X, y):
    model.fit(X, y)
    return model

def test_model(model, X):
    return model.predict(X)

if __name__ == '__main__':

    models = {"LinearRegression": LinearRegression(),
              "NaiveBayes": GaussianNB(),
              "KNearestNeighbour": KNeighborsClassifier(), 
              "DecisionTree": DecisionTreeClassifier(),
              "AdaBoost": AdaBoostClassifier(n_estimators=100), 
              "RandomForest": RandomForestClassifier(n_estimators=100)}
              
    table = PrettyTable(["Model", "Accuracy", "Precision", "Recall", "F1-score"])

    X_train, y_train, X_test, y_test = generate_train_test_data("data/kddtrain.csv", "data/kddtest.csv")
    for key, value in models.items():
        model = train_model(value, X_train, y_train)
        dump(model, 'models/'+key+'.joblib') 

    print("Training done..")